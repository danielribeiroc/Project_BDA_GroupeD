{
 "metadata": {
  "name": "Model_1_refactored",
  "kernelspec": {
   "language": "scala",
   "name": "spark2-scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Modèle 1 : Prédiction de la Victoire de l'Équipe à Domicile ou en Déplacement Basée sur les Statistiques d'un Match\n",
    "\n",
    "Ce Zeppelin notebook décrit le processus complet pour créer un modèle de prédiction des résultats de matchs de foot. Bien que le cours porte sur le big data, nous avons tenté d'utiliser des méthodes et des traitements de données typiques du big data, malgré un nombre de données d'entraînement relativement limité (nous possédons pour ce model de **10Gb de données**). Il est donc important de prendre cela en compte. Les fonctions utilisées ont été développées par nous même et en consultant des exemples en ligne et en se référant à la documentation, et chaque fonction complexe a été expliquée pour illustrer le processus de traitement.\n",
    "\n",
    "### Prétraitement des Données\n",
    "\n",
    "Le dossier `./data/events` contient plusieurs fichiers JSON, chacun étant nommé avec un identifiant unique représentant un match dans le dataset. Le contenu de chaque fichier est à la fois vaste et bien structuré, comme documenté dans le [répertoire GitHub de StatsBomb](https://github.com/statsbomb/open-data/tree/master/doc). Chaque fichier inclut toutes les actions du match, telles que chaque passe, tir, carton jaune, réception, arrêt de balle, etc. Nous avons donc supposé qu'il était possible de regrouper les statistiques d'un match pour créer un modèle capable de prédire laquelle des deux équipes remportera le match.\n",
    "\n",
    "### Features Définies\n",
    "\n",
    "Pour les deux équipes, nous avons défini un total de 21 features. Ces features permettent de décrire le match en question. Les features avec les valeurs `team1` ou `home` se réfèrent à l'équipe à domicile, tandis que celles avec `team2` ou `away` concernent l'équipe en déplacement.\n",
    "\n",
    "#### Liste des Features\n",
    "```\n",
    "root\n",
    " |-- match_id: string (non utilisé)\n",
    " |-- match_teams: string (non utilisé)\n",
    " |-- Pass_team1: long (utilisé)\n",
    " |-- Pass_team2: long (utilisé)\n",
    " |-- Shot_team1: long (utilisé)\n",
    " |-- Shot_team2: long (utilisé)\n",
    " |-- Foul_won_team1: long (utilisé)\n",
    " |-- Foul_won_team2: long (utilisé)\n",
    " |-- Foul_committed_team1: long (utilisé)\n",
    " |-- Foul_committed_team2: long (utilisé)\n",
    " |-- Bad_Behaviour_Yellow_Card_team1: long (utilisé)\n",
    " |-- Bad_Behaviour_Yellow_Card_team2: long (utilisé)\n",
    " |-- total_red_cards_team1: long (utilisé)\n",
    " |-- total_red_cards_team2: long (utilisé)\n",
    " |-- total_actions_team1: long (utilisé)\n",
    " |-- total_actions_team2: long (utilisé)\n",
    " |-- match_date: string (utilisé)\n",
    " |-- home_score: long (utilisé)\n",
    " |-- away_score: long (utilisé)\n",
    " |-- home_team_id: long (utilisé)\n",
    " |-- team1_results: double (utilisé)\n",
    " |-- away_team_id: long (utilisé)\n",
    " |-- team2_results: double (utilisé)\n",
    " |-- winning_team: string (non utilisé) --> utilisé pour la ground truth (valeur y)\n",
    "```\n",
    "\n",
    "Ce modèle et ces données nous permettent de prédire le vainqueur d'un match en se basant sur les statistiques des équipes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définitin des variables statiques\n",
    "\n",
    "Afin de permettre le bon fonctionnement, du zeppelin nous définissons ici des variables statiques qui permettent de facilement récupérer les données nécessaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "val jsonDirectory = \"./data/events\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Créations des features \n",
    "\n",
    "Nous abordons ici une étape importante : la création des features principales. Bien que le code soit relativement long en raison du nombre de features à générer, chaque section est expliquée à l'aide de commentaires pour faciliter la compréhension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.hadoop.fs.{FileSystem, Path}\n",
    "\n",
    "// Partie où nous définissons la session Spark\n",
    "val spark = SparkSession.builder.appName(\"Soccer Match Analysis\").getOrCreate()\n",
    "val sc = spark.sparkContext\n",
    "val hadoopConf = sc.hadoopConfiguration\n",
    "val fs = FileSystem.get(hadoopConf)\n",
    "val fileStatus = fs.listStatus(new Path(jsonDirectory))\n",
    "val files = fileStatus.map(_.getPath.toString)\n",
    "\n",
    "// Lecture de tous les fichiers JSON dans un DataFrame Spark\n",
    "val allMatchesDf = spark.read.option(\"multiLine\", true).json(files: _*)\n",
    "\n",
    "// Récupération de l'ID du match à partir du nom du fichier (ex: 657.json = 657)\n",
    "val filePathColumn = input_file_name()\n",
    "val matchIdDf = allMatchesDf.withColumn(\"match_id\", regexp_extract(filePathColumn, \"\"\"(\\d+)\\.json$\"\"\", 1))\n",
    "\n",
    "val startTime = System.nanoTime()\n",
    "\n",
    "// Définition des features basées sur les types d'actions dans le match --> types d actions basiques\n",
    "val featureColumns2 = Seq(\n",
    "  (\"type.name\", \"Pass\", \"Pass_feature\"),\n",
    "  (\"type.name\", \"Shot\", \"Shot_feature\"),\n",
    "  (\"type.name\", \"Foul Won\", \"Foul_won_feature\"),\n",
    "  (\"type.name\", \"Foul Committed\", \"Foul_committed_feature\")\n",
    ")\n",
    "\n",
    "// Définition des features pour les cartons et actions spécifiques du gardien de but\n",
    "val featureColumns3 = Seq(\n",
    "  (\"type.name\", \"Bad Behaviour\", \"bad_behaviour.card.name\", \"Yellow Card\", \"Bad_Behaviour_Yellow_Card_feature\"),\n",
    "  (\"type.name\", \"Bad Behaviour\", \"bad_behaviour.card.name\", \"Second Yellow\", \"Bad_Behaviour_Second_Yellow_feature\"),\n",
    "  (\"type.name\", \"Goal Keeper\", \"goalkeeper.type.name\", \"Penalty Saved\", \"Goalkeeper_Penalty_Saved_feature\"),\n",
    "  (\"type.name\", \"Goal Keeper\", \"goalkeeper.type.name\", \"Punch\", \"Goalkeeper_Punch_feature\"),\n",
    "  (\"type.name\", \"Goal Keeper\", \"goalkeeper.type.name\", \"Save\", \"Goalkeeper_Save_feature\"),\n",
    "  (\"type.name\", \"Goal Keeper\", \"goalkeeper.type.name\", \"Shot Saved\", \"Goalkeeper_Shot_Saved_feature\"),\n",
    "  (\"type.name\", \"Goal Keeper\", \"goalkeeper.type.name\", \"Smother\", \"Goalkeeper_Smother_feature\"),\n",
    "  (\"type.name\", \"Goal Keeper\", \"goalkeeper.type.name\", \"Shot Saved To Post\", \"Goalkeeper_Shot_Saved_To_Post_feature\")\n",
    ")\n",
    "\n",
    "// Définition des features pour les cartons rouges et deuxiémes cartons\n",
    "val featureColumnsSeq = Seq(\n",
    "  (\"type.name\", \"Bad Behaviour\", \"bad_behaviour.card.name\", Seq(\"Red Card\", \"Second Yellow\"), \"Bad_Behaviour_Red_Card_feature\")\n",
    ")\n",
    "\n",
    "// Ajout des colonnes de features au DataFrame pour les types d'actions de base\n",
    "val updatedDf2 = featureColumns2.foldLeft(matchIdDf)((df, colInfo) => {\n",
    "  val (col1, col2, newCol) = colInfo // On prend la séquence 1 de features column comme exemple --> (\"type.name\", \"Pass\", \"Pass_feature\")\n",
    "  df.withColumn(newCol, when(col(col1) === col2, 1).otherwise(0)) // newCol = le nom de la nouvelle colonne dans matchIdDf,  si la col1 (type.name) est = Bad Behaviour alors on mets un 1 à cette emplacement sinon 0 et ainsi de suite pour chaque object\n",
    "})\n",
    "\n",
    "// Ajout des colonnes de features pour les cartons et actions spécifiques --> le fonctionnement est le meme que pour la fonction précédente\n",
    "val updatedDf3 = featureColumns3.foldLeft(updatedDf2)((df, colInfo) => {\n",
    "  val (col1, col2, col3, col4, newCol) = colInfo\n",
    "  df.withColumn(newCol, when(col(col1) === col2 && col(col3) === col4, 1).otherwise(0))\n",
    "})\n",
    "\n",
    "// Ajout des colonnes de features pour les cartons rouges et deuxiémes cartons --> le fonctionnement est le meme que pour la fonction précédente\n",
    "val updatedDfSeq = featureColumnsSeq.foldLeft(updatedDf3)((df, colInfo) => {\n",
    "  val (col1, col2, col3, col4, newCol) = colInfo\n",
    "  df.withColumn(newCol, when(col(col1) === col2 && col(col3).isin(col4: _*), 1).otherwise(0)) // la fonction col(col3).isin(col4: _*) permet de dire que si col3 contient une des valeurs dans col4 (Seq(\"Red Card\", \"Second Yellow\"))\n",
    "})\n",
    "\n",
    "// Agrégation des features par match et par équipe avec la somme de chaque --> renommé chaque colonne car plus simple\n",
    "val aggregatedDf = updatedDfSeq.groupBy(\"match_id\", \"possession_team.name\").agg(\n",
    "  sum(\"Pass_feature\").alias(\"Pass\"),\n",
    "  sum(\"Shot_feature\").alias(\"Shot\"),\n",
    "  sum(\"Foul_won_feature\").alias(\"Foul_won\"),\n",
    "  sum(\"Foul_committed_feature\").alias(\"Foul_committed\"),\n",
    "  sum(\"Bad_Behaviour_Yellow_Card_feature\").alias(\"Bad_Behaviour_Yellow_Card\"),\n",
    "  sum(\"Bad_Behaviour_Second_Yellow_feature\").alias(\"Bad_Behaviour_Second_Yellow\"),\n",
    "  sum(\"Bad_Behaviour_Red_Card_feature\").alias(\"Bad_Behaviour_Red_Card\"),\n",
    "  sum(\"Goalkeeper_Penalty_Saved_feature\").alias(\"Goalkeeper_Penalty_Saved\"),\n",
    "  sum(\"Goalkeeper_Punch_feature\").alias(\"Goalkeeper_Punch\"),\n",
    "  sum(\"Goalkeeper_Save_feature\").alias(\"Goalkeeper_Save\"),\n",
    "  sum(\"Goalkeeper_Shot_Saved_feature\").alias(\"Goalkeeper_Shot_Saved\"),\n",
    "  sum(\"Goalkeeper_Smother_feature\").alias(\"Goalkeeper_Smother\"),\n",
    "  sum(\"Goalkeeper_Shot_Saved_To_Post_feature\").alias(\"Goalkeeper_Shot_Saved_To_Post\")\n",
    ")\n",
    "\n",
    "// Jointure des données agrégées pour les deux équipes dans un même match\n",
    "val joinedDf = aggregatedDf.as(\"df1\")\n",
    "  .join(aggregatedDf.as(\"df2\"), col(\"df1.match_id\") === col(\"df2.match_id\") && col(\"df1.name\") < col(\"df2.name\"))\n",
    "  .select(\n",
    "    col(\"df1.match_id\"),\n",
    "    concat_ws(\" vs \", col(\"df1.name\"), col(\"df2.name\")).alias(\"match_teams\"),\n",
    "    col(\"df1.Pass\").alias(\"Pass_team1\"),\n",
    "    col(\"df2.Pass\").alias(\"Pass_team2\"),\n",
    "    col(\"df1.Shot\").alias(\"Shot_team1\"),\n",
    "    col(\"df2.Shot\").alias(\"Shot_team2\"),\n",
    "    col(\"df1.Foul_won\").alias(\"Foul_won_team1\"),\n",
    "    col(\"df2.Foul_won\").alias(\"Foul_won_team2\"),\n",
    "    col(\"df1.Foul_committed\").alias(\"Foul_committed_team1\"),\n",
    "    col(\"df2.Foul_committed\").alias(\"Foul_committed_team2\"),\n",
    "    col(\"df1.Bad_Behaviour_Yellow_Card\").alias(\"Bad_Behaviour_Yellow_Card_team1\"),\n",
    "    col(\"df2.Bad_Behaviour_Yellow_Card\").alias(\"Bad_Behaviour_Yellow_Card_team2\"),\n",
    "    (col(\"df1.Bad_Behaviour_Red_Card\") + col(\"df1.Bad_Behaviour_Second_Yellow\")).alias(\"total_red_cards_team1\"),\n",
    "    (col(\"df2.Bad_Behaviour_Red_Card\") + col(\"df2.Bad_Behaviour_Second_Yellow\")).alias(\"total_red_cards_team2\"),\n",
    "    (col(\"df1.Goalkeeper_Penalty_Saved\") +\n",
    "      col(\"df1.Goalkeeper_Punch\") +\n",
    "      col(\"df1.Goalkeeper_Save\") +\n",
    "      col(\"df1.Goalkeeper_Shot_Saved\") +\n",
    "      col(\"df1.Goalkeeper_Smother\") +\n",
    "      col(\"df1.Goalkeeper_Shot_Saved_To_Post\")).alias(\"total_actions_team1\"),\n",
    "    (col(\"df2.Goalkeeper_Penalty_Saved\") +\n",
    "      col(\"df2.Goalkeeper_Punch\") +\n",
    "      col(\"df2.Goalkeeper_Save\") +\n",
    "      col(\"df2.Goalkeeper_Shot_Saved\") +\n",
    "      col(\"df2.Goalkeeper_Smother\") +\n",
    "      col(\"df2.Goalkeeper_Shot_Saved_To_Post\")).alias(\"total_actions_team2\")\n",
    "  )\n",
    "\n",
    "val endTime = System.nanoTime()\n",
    "val duration = (endTime - startTime) / 1e9d\n",
    "println(s\"Time taken: $duration seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all matches from local file --> see other notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.DataFrame\n",
    "\n",
    "val spark = SparkSession.builder\n",
    "  .appName(\"Load Football Matches Analysis\")\n",
    "  .getOrCreate()\n",
    "\n",
    "\n",
    "val matchesDf = spark.read.parquet(\"./data/all_matches.parquet\")\n",
    "\n",
    "matchesDf.printSchema()\n",
    "matchesDf.show()\n",
    "val totalMatches = matchesDf.count()\n",
    "println(s\"Total number of matches: $totalMatches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajouter aux vecteurs les derniers scores des équipes (2 derniers matchs) et ajouter une colonne y qui concerne l'équipe qui a gagner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.expressions.Window\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "// Enrichir le DataFrame avec des informations supplémentaires sur les matchs\n",
    "val enrichedDf = joinedDf.join(matchesDf.select(\"match_id\", \"match_date\", \"home_team_id\", \"away_team_id\", \"home_score\", \"away_score\"), Seq(\"match_id\"))\n",
    "\n",
    "// Fonction pour calculer les résultats des deux derniers matchs pour une équipe donnée\n",
    "def calculateLastTwoResults(teamId: String, teamColumn: String, scoreColumn: String, opponentScoreColumn: String): DataFrame = {\n",
    "    \n",
    "  // Définition d'une Window pour partitionner par équipe et ordonner par date de match en ordre décroissant\n",
    "  val windowSpec = Window.partitionBy(teamId).orderBy($\"match_date\".desc) // fonction très importante de trier par date\n",
    "\n",
    "  matchesDf\n",
    "    .withColumn(\"row_number\", row_number().over(windowSpec)) // Ajout d'un numéro de ligne pour chaque partition\n",
    "    .withColumn(\"result\", when(col(scoreColumn) > col(opponentScoreColumn), 1.0) // Calcul du résultat du match (1.0 pour victoire, 0.5 pour match nul, 0.0 pour défaite)\n",
    "                          .when(col(scoreColumn) === col(opponentScoreColumn), 0.5)\n",
    "                          .otherwise(0.0))\n",
    "    .filter($\"row_number\" <= 2) // Filtrer pour ne conserver que les deux derniers matchs\n",
    "    .groupBy(teamId) // GroupBy par équipe et agg les résultats des deux derniers matchs\n",
    "    .agg(sum(\"result\").alias(s\"${teamColumn}_results\"))\n",
    "    \n",
    "    // Normaliser les résultats sur une échelle de 0 à 1 (moyenne des deux derniers résultats)\n",
    "    .withColumn(s\"${teamColumn}_results\", when(col(s\"${teamColumn}_results\").isNull, 0.0)\n",
    "                                          .otherwise(col(s\"${teamColumn}_results\") / 2.0))\n",
    "}\n",
    "\n",
    "// Calcul des résultats des deux derniers matchs pour l'équipe à domicile et extérieur\n",
    "val homeTeamResults = calculateLastTwoResults(\"home_team_id\", \"team1\", \"home_score\", \"away_score\")\n",
    "val awayTeamResults = calculateLastTwoResults(\"away_team_id\", \"team2\", \"away_score\", \"home_score\")\n",
    "\n",
    "// Joindre les résultats calculés avec le nouveau df\n",
    "val finalDf = enrichedDf\n",
    "  .join(homeTeamResults, enrichedDf(\"home_team_id\") === homeTeamResults(\"home_team_id\"), \"left\")\n",
    "  .drop(homeTeamResults(\"home_team_id\"))\n",
    "  .join(awayTeamResults, enrichedDf(\"away_team_id\") === awayTeamResults(\"away_team_id\"), \"left\")\n",
    "  .drop(awayTeamResults(\"away_team_id\"))\n",
    "\n",
    "// Ajouter la colonne \"winning_team\" avec les valeurs \"home_team\", \"away_team\" ou \"draw\"\n",
    "val finalDfWithWinningTeam = finalDf.withColumn(\"winning_team\", \n",
    "  when(col(\"home_score\") > col(\"away_score\"), \"home_team\")\n",
    "  .when(col(\"home_score\") < col(\"away_score\"), \"away_team\")\n",
    "  .otherwise(\"draw\")\n",
    ")\n",
    "\n",
    "finalDfWithWinningTeam.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "finalDfWithWinningTeam.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dernier filtre du preprocessing du dataset\n",
    "\n",
    "Pour cette analyse, nous avons décidé de retirer les matchs qui se sont terminés sur un score d'égalité. Cette décision est motivée par plusieurs essais préliminaires qui ont montré que le nombre de matchs nuls est très faible comparé aux matchs avec un vainqueur. Cela crée un \"unbalanced data\" dans les données, rendant l'amélioration de notre modèle très compliquée. En excluant ces matchs, nous avons pu obtenir des résultats plus fiables et une meilleure performance du modèle.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "val filteredDf = finalDfWithWinningTeam.filter(col(\"winning_team\") =!= \"draw\") // Filtrer le DataFrame pour ne conserver que les matchs avec un gagnant (exclure les matchs nuls) comme dit\n",
    "\n",
    "\n",
    "//Afficher les victoires des 2 équipes\n",
    "val teamWins = filteredDf.groupBy(\"winning_team\").count()\n",
    "teamWins.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with Spark ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.ml.feature.{VectorAssembler, StringIndexer, OneHotEncoder}\n",
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "\n",
    "val spark = SparkSession.builder()\n",
    "  .appName(\"WinningTeamPrediction\")\n",
    "  .getOrCreate()\n",
    "\n",
    "val schema = new StructType()\n",
    "  .add(\"match_id\", StringType, false)\n",
    "  .add(\"match_teams\", StringType, false)\n",
    "  .add(\"Pass_team1\", LongType, true)\n",
    "  .add(\"Pass_team2\", LongType, true)\n",
    "  .add(\"Shot_team1\", LongType, true)\n",
    "  .add(\"Shot_team2\", LongType, true)\n",
    "  .add(\"Foul_won_team1\", LongType, true)\n",
    "  .add(\"Foul_won_team2\", LongType, true)\n",
    "  .add(\"Foul_committed_team1\", LongType, true)\n",
    "  .add(\"Foul_committed_team2\", LongType, true)\n",
    "  .add(\"Bad_Behaviour_Yellow_Card_team1\", LongType, true)\n",
    "  .add(\"Bad_Behaviour_Yellow_Card_team2\", LongType, true)\n",
    "  .add(\"total_red_cards_team1\", LongType, true)\n",
    "  .add(\"total_red_cards_team2\", LongType, true)\n",
    "  .add(\"total_actions_team1\", LongType, true)\n",
    "  .add(\"total_actions_team2\", LongType, true)\n",
    "  .add(\"match_date\", StringType, true)\n",
    "  .add(\"home_score\", LongType, true)\n",
    "  .add(\"away_score\", LongType, true)\n",
    "  .add(\"home_team_id\", LongType, true)\n",
    "  .add(\"team1_results\", DoubleType, true)\n",
    "  .add(\"away_team_id\", LongType, true)\n",
    "  .add(\"team2_results\", DoubleType, true)\n",
    "  .add(\"winning_team\", StringType, false)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.classification.{LogisticRegression, LinearSVC, GBTClassifier, RandomForestClassifier}\n",
    "import org.apache.spark.ml.tuning.{ParamGridBuilder, CrossValidator}\n",
    "\n",
    "// Step 1\n",
    "val featureCols = Array(\"Pass_team1\", \"Pass_team2\", \"Shot_team1\", \"Shot_team2\", \"Foul_won_team1\", \"Foul_won_team2\", \n",
    "  \"Foul_committed_team1\", \"Foul_committed_team2\", \"Bad_Behaviour_Yellow_Card_team1\", \n",
    "  \"Bad_Behaviour_Yellow_Card_team2\", \"total_red_cards_team1\", \"total_red_cards_team2\", \n",
    "  \"total_actions_team1\", \"total_actions_team2\", \"team1_results\", \"team2_results\")\n",
    "\n",
    "val assembler = new VectorAssembler()\n",
    "  .setInputCols(featureCols)\n",
    "  .setOutputCol(\"features\")\n",
    "\n",
    "// Step 2\n",
    "val labelIndexer = new StringIndexer()\n",
    "  .setInputCol(\"winning_team\")\n",
    "  .setOutputCol(\"label\")\n",
    "  .fit(filteredDf)\n",
    "\n",
    "val indexedData = labelIndexer.transform(filteredDf)\n",
    "\n",
    "// Step 3\n",
    "val Array(trainingData, testData) = indexedData.randomSplit(Array(0.8, 0.2))\n",
    "\n",
    "// Step 4\n",
    "val lr = new LogisticRegression()\n",
    "  .setLabelCol(\"label\")\n",
    "  .setFeaturesCol(\"features\")\n",
    "  .setMaxIter(10)\n",
    "\n",
    "val rf = new RandomForestClassifier()\n",
    "  .setLabelCol(\"label\")\n",
    "  .setFeaturesCol(\"features\")\n",
    "\n",
    "// Step 5\n",
    "val lrParamGrid = new ParamGridBuilder()\n",
    "  .addGrid(lr.regParam, Array(0.1, 0.01))\n",
    "  .addGrid(lr.elasticNetParam, Array(0.0, 0.5, 1.0))\n",
    "  .build()\n",
    "\n",
    "val rfParamGrid = new ParamGridBuilder()\n",
    "  .addGrid(rf.numTrees, Array(20, 50))\n",
    "  .addGrid(rf.maxDepth, Array(5, 10))\n",
    "  .build()\n",
    "\n",
    "// Step 6\n",
    "val evaluator = new MulticlassClassificationEvaluator()\n",
    "  .setLabelCol(\"label\")\n",
    "  .setPredictionCol(\"prediction\")\n",
    "  .setMetricName(\"accuracy\")\n",
    "\n",
    "// Step 7\n",
    "val lrCv = new CrossValidator()\n",
    "  .setEstimator(lr)\n",
    "  .setEvaluator(evaluator)\n",
    "  .setEstimatorParamMaps(lrParamGrid)\n",
    "  .setNumFolds(3)\n",
    "\n",
    "val rfCv = new CrossValidator()\n",
    "  .setEstimator(rf)\n",
    "  .setEvaluator(evaluator)\n",
    "  .setEstimatorParamMaps(rfParamGrid)\n",
    "  .setNumFolds(3)\n",
    "\n",
    "// Step 8\n",
    "val lrPipeline = new Pipeline().setStages(Array(assembler, lrCv))\n",
    "val rfPipeline = new Pipeline().setStages(Array(assembler, rfCv))\n",
    "\n",
    "// Train the models\n",
    "val lrModel = lrPipeline.fit(trainingData)\n",
    "val rfModel = rfPipeline.fit(trainingData)\n",
    "\n",
    "// Make predictions\n",
    "val lrPredictions = lrModel.transform(testData)\n",
    "val rfPredictions = rfModel.transform(testData)\n",
    "\n",
    "// Evaluate the models\n",
    "val lrAccuracy = evaluator.evaluate(lrPredictions)\n",
    "val rfAccuracy = evaluator.evaluate(rfPredictions)\n",
    "\n",
    "println(s\"Logistic Regression Test set accuracy = $lrAccuracy\")\n",
    "println(s\"Random Forest Test set accuracy = $rfAccuracy\")\n",
    "\n",
    "//lrPredictions.select(\"match_id\", \"winning_team\", \"prediction\").show(10)\n",
    "//rfPredictions.select(\"match_id\", \"winning_team\", \"prediction\").show(10)"
   ]
  }
 ]
}
